# Deep-Learning-Charity-Funding-Predictor
The Purpose of this Analysis was to determine whether or not there is a way to predict the successfulness of a charity based on certain classifiers. 
Successfulness is the measure of whether or not the target goal was reached, making successful a binary variable. Most of the other measures were used as features of the model. This includes Application_Type, Affiliation, Classification, Use_Case, Organization, Status, Income_Amt, Special_Considerations, and Ask_Amt. After cleaning the data in the features (by dropping unwanted classifiers and binning repeated value counts), the data was split into testing and training data. That data was then scaled to be put into a model.
The original model contained 100 neurons, with 60 in the first layer and 40 in the second layer, that fed into an output layer. The amount of neurons were chosen arbitrarily. The two hidden layers had a ‘relu’ activation, while the output layer had a ‘sigmoid’ layer. These were chosen out of practice. This model was then compiled and fit to the data, training in 100 epochs. With this, the model’s accuracy was about .72, just under the target of .75. 
To increase the model performance, first, the ‘name’ category removed from the beginning was re-added to the dataset. The ‘name’ column actually contained somewhat categorical variable as some of the charities that were in the category had multiple locations. When creating dummy variables with the new data frame, the size of the data frame more than doubled. Because of this, more neurons were added to a third hidden layer in order to better find patterns in this additional data. Because of these two steps target performance shot up to .77. 
These results show that with a good sized dataset, that contains a lot of descriptive categorical data, this model can be made to be very accurate. From this data set, we see that adding a variable and more neurons was able to tweak the algorithm and increase accuracy. I recommend that this model be tweaked by rearranging the features and the neurons.
